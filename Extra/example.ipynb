{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=m3WwttSBDvo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import VectorStoreRetrieverMemory\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "\n",
    "load_dotenv()\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from milvus import default_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_server.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import utility, connections\n",
    "\n",
    "connections.connect(host='127.0.0.1', port=default_server.listen_port)\n",
    "utility.drop_collection('LangChainCollection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Milvus.from_documents(\n",
    "    {},\n",
    "    embeddings,\n",
    "    connections_args = {'host':'127.0.0.1', 'port':default_server.listen_port()}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = Milvus.as_retriever(vectordb, search_kwargs = dict(k = 20))\n",
    "memory = VectorStoreRetrieverMemory(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "about_me = [\n",
    "    {\"input\":\"My favorite snack is chocolate\", \n",
    "     \"output\":\"Nice\"},\n",
    "     {\"input\":\"My favorite color is blue\", \n",
    "     \"output\":\"Cool\"},\n",
    "     {\"input\":\"My favorite sport is futbol\", \n",
    "     \"output\":\"Sweet\"},\n",
    "     {\"input\":\"my favorite drink is beer\", \n",
    "     \"output\":\"Good to know\"},\n",
    "]\n",
    "\n",
    "for example in about_me:\n",
    "    memory.save_context({\"input\": example['input']}, {\"output\":example['output']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_together import Together\n",
    "llm = Together(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    temperature=0,\n",
    "    max_tokens=256,\n",
    "    top_k=1,\n",
    "    together_api_key=os.getenv(\"TOGETHER_API_KEY\")\n",
    ")\n",
    "\n",
    "DEFAULT_TEMPLATE = \"\"\"The following exchange is a friendly conversation between a human and an AI. The AI is talkative and provides a lot of specific details of its context.\n",
    "If the AI does not know the answer to the question, it will truthfully sai it does not know\n",
    "\n",
    "Relevant pieces of previous conversations:\n",
    "{history}\n",
    "\n",
    "Current Conversation:\n",
    "Human: {input}\n",
    "AI:\"\"\"\n",
    "\n",
    "PROMPT = PromptTemplate(\n",
    "    input_variables=['history', 'input'], template=DEFAULT_TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    prompt=PROMPT,\n",
    "    memory = memory,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain.predict(input=\"Hi, my name is Yugi Moto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain.predict(input=\"who is my favorite musician?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain.predict(input='What is my favorite sport')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_chain.predict(input='What is my name?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_server.stop()\n",
    "default_server.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
